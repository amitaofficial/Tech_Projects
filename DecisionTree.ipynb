{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM93ua9N83u6wh97iNRgvMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitaofficial/Tech_Projects/blob/main/DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Me:\n",
        "# 1. Training data should be in a text file named 'train.txt'and test data in 'test.txt'.\n",
        "# 2. I have attached train.txt (first 90 data points) and test.txt(last 30 data points) which i got for my student id\n",
        "# 3. maximum depth of the tree can be changed at line number 4, by changing the value to variable 'given_depth'\n",
        "# Author - Amita Ghosh (1001841234)\n",
        "# References: # https://stackoverflow.com/questions/903853/how-do-you-extract-a-column-from-a-multi-dimensional-array\n",
        "              # https://towardsdatascience.com/decision-tree-algorithm-in-python-from-scratch-8c43f0e40173\n",
        "              # S. Russell and P. Norvig, \"Artificial Intelligence: A Modern Approach\"\n"
      ],
      "metadata": {
        "id": "iA1OevQ73XCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "given_depth = 3 #mention the maximum depth here"
      ],
      "metadata": {
        "id": "a095nipXMJn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate entropy of a given dataset\n",
        "def calculate_entropy(data_array):\n",
        "  data_count = len(data_array)\n",
        "  if(data_count == 0):#checking if data is present or not\n",
        "    return 1\n",
        "  M_count = 0\n",
        "  W_count = 0\n",
        "  for data in data_array:\n",
        "    if(data[3] == 'M'):\n",
        "      M_count += 1 #count the number of data with 'M' class\n",
        "    else:\n",
        "      W_count += 1 #count the number of data with 'W' class\n",
        "\n",
        "  # print('M:', M_count,'/', data_count)\n",
        "  # print('W:',W_count,'/', data_count)\n",
        "\n",
        "  p1 = M_count / data_count # calculate probability of 'M'\n",
        "  p2 = W_count / data_count # calculate probability of 'W'\n",
        "  if(p1 > 0 and p2 > 0): # check if probabilities are greater than 0 to avoid 0 * 0 multiplication\n",
        "    H = -(p1 * math.log2(p1)) - (p2 * math.log2(p2))  \n",
        "    return H\n",
        "  elif (p1 > 0):\n",
        "    return -(p1 * math.log2(p1))\n",
        "  elif (p2 > 0):\n",
        "    return -(p2 * math.log2(p2))\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "ECrVu2ZqqhSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to choose the right attribute-threshold combo for the next node\n",
        "def choose_attribute(data_array,no_of_attributes):\n",
        "  best_threshold = 0.0 # best threshold that gives highest info.gain\n",
        "  best_attribute = 0 # best attribute that gives highest info.gain\n",
        "  best_gain = 0.0 #best gain out of all attribute-threshold combinations\n",
        "  for k in range(no_of_attributes):\n",
        "    #sort feature\n",
        "    f = [row[k] for row in data_array] #get the column feature\n",
        "    f.sort()\n",
        "    #calculating thresholds\n",
        "    f_thresholds = []\n",
        "    for i in range(len(f)-1):\n",
        "      threshold = (f[i]+f[i+1])/2\n",
        "      f_thresholds.append(threshold)\n",
        "    # print('Attribute No : ',k+1)\n",
        "    \n",
        "    #calculate before split entropy\n",
        "    H_initial = calculate_entropy(data_array)\n",
        "    # print('H_initial:',H_initial)\n",
        "    \n",
        "    #calculate entropy after split for each threshold\n",
        "    data_before_split = data_array\n",
        "    selected_threshold = 0.0\n",
        "    max_gain = 0.0\n",
        "    for threshold in f_thresholds:\n",
        "      # print('threshold is : ',threshold)\n",
        "      data_after_split_left = []\n",
        "      data_after_split_right = []\n",
        "      for data in data_array:\n",
        "        if(data[k] <= threshold):\n",
        "          data_after_split_left.append(data)\n",
        "        else:\n",
        "          data_after_split_right.append(data)\n",
        "      #calculate entropy after split\n",
        "      # print('left split :')\n",
        "      H1 = calculate_entropy(data_after_split_left)\n",
        "      # print('H1: ',H1)\n",
        "      # print('right split :')\n",
        "      H2 = calculate_entropy(data_after_split_right)\n",
        "      p_H1 = len(data_after_split_left)/len(data_before_split)\n",
        "      # print('H2: ',H2)\n",
        "      p_H2 = len(data_after_split_right)/len(data_before_split)\n",
        "      H_after_split = (p_H1*H1) + (p_H2*H2)\n",
        "      information_gain = H_initial - H_after_split\n",
        "      # print('H_initial - [(',len(data_after_split_left),'/',len(data_before_split),')* H1 + (',len(data_after_split_right),'/',len(data_before_split),')* H2]')\n",
        "      # print('information_gain: ',information_gain)\n",
        "      # print('*****************************************')\n",
        "      if(information_gain > max_gain):\n",
        "        max_gain = information_gain\n",
        "        selected_threshold = threshold\n",
        "        # print('feature :',k)\n",
        "        # print('max_gain:',max_gain)\n",
        "        # print('selected_threshold:',selected_threshold)\n",
        "    if(max_gain > best_gain):\n",
        "      best_gain = max_gain\n",
        "      best_threshold = selected_threshold\n",
        "      best_attribute = k\n",
        "  # print('################################')\n",
        "  # print('best_threshold:',best_threshold)\n",
        "  # print('best_attribute:',best_attribute)\n",
        "  # print('################################')\n",
        "  return (best_attribute,best_threshold)"
      ],
      "metadata": {
        "id": "CrGDJBP1V99l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_on_left(best_attribute,best_threshold,data_array):\n",
        "  data_after_split_left = []\n",
        "  for data in data_array:\n",
        "    if(data[best_attribute] <= best_threshold):\n",
        "      data_after_split_left.append(data)\n",
        "  return data_after_split_left\n",
        "\n",
        "def get_data_on_right(best_attribute,best_threshold,data_array):\n",
        "  data_after_split_right = []\n",
        "  for data in data_array:\n",
        "    if(data[best_attribute] > best_threshold):\n",
        "      data_after_split_right.append(data)\n",
        "  return data_after_split_right\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "Vge3zIZFrCRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_class(data_array):\n",
        "  M_count = 0\n",
        "  W_count = 0\n",
        "  for data in data_array:\n",
        "    if(data[3] == 'M'):\n",
        "      M_count += 1\n",
        "    else:\n",
        "      W_count += 1\n",
        "  if(M_count > W_count):\n",
        "    return Node(None,None,None,'M')\n",
        "  else:\n",
        "    return Node(None,None,None,'W')"
      ],
      "metadata": {
        "id": "0czhGmXvzVXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "\n",
        "  def __init__(self,attribute,threshold,depth,class_label):\n",
        "    self.left_node = None\n",
        "    self.right_node = None\n",
        "    self.max_depth = given_depth\n",
        "    self.depth = depth\n",
        "    self.attribute = attribute\n",
        "    self.threshold = threshold\n",
        "    self.class_label = class_label\n",
        "\n",
        "\n",
        "  def print_tree(self):\n",
        "    print(self.attribute,self.class_label)\n",
        "    if self.left_node is not None: \n",
        "        self.left_node.print_tree()\n",
        "    \n",
        "    if self.right_node is not None:\n",
        "        self.right_node.print_tree()\n",
        "\n",
        "  def predict(self,data,max_depth):\n",
        "    x1,x2,x3 = data\n",
        "    temp = {0:x1,1:x2,2:x3}\n",
        "    current_node = self\n",
        "    i = 0\n",
        "    while(i < max_depth):\n",
        "      if(current_node.attribute in temp):\n",
        "        if(temp[current_node.attribute] > current_node.threshold):\n",
        "          if current_node.right_node is not None:\n",
        "            current_node = current_node.right_node\n",
        "        else:\n",
        "          if current_node.left_node is not None: \n",
        "            current_node = current_node.left_node\n",
        "        i += 1\n",
        "      else:\n",
        "        return current_node.class_label\n",
        "\n",
        "    # print('######',current_node.class_label)\n",
        "    return current_node.class_label"
      ],
      "metadata": {
        "id": "7OE2FCL2tLsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DTL(data_array,attributes,default,depth,max_depth,best_threshold):\n",
        "  if(best_threshold == 0.0):\n",
        "    return default\n",
        "  if(len(data_array) == 0):\n",
        "    return default\n",
        "  elif(depth == max_depth):\n",
        "    return default\n",
        "  else:\n",
        "    best_attribute,best_threshold = choose_attribute(data_array,attributes)\n",
        "    if(best_threshold == 0.0):\n",
        "      return default\n",
        "    else:\n",
        "      tree = Node(best_attribute,best_threshold,depth,None)\n",
        "      left_data_set = get_data_on_left(best_attribute,best_threshold,data_array)\n",
        "      right_data_set = get_data_on_right(best_attribute,best_threshold,data_array)\n",
        "      tree.left_node = DTL(left_data_set,attributes,get_default_class(left_data_set),depth+1,max_depth,best_threshold)\n",
        "      tree.right_node = DTL(right_data_set,attributes,get_default_class(right_data_set),depth+1,max_depth,best_threshold)\n",
        "\n",
        "      return tree"
      ],
      "metadata": {
        "id": "pl6K-yOOvu9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dael6g3BFXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fceed6-51ab-41a2-9afa-62d5c025e839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 None\n",
            "0 None\n",
            "2 None\n",
            "None W\n",
            "None M\n",
            "0 None\n",
            "None M\n",
            "None W\n",
            "0 None\n",
            "0 None\n",
            "None M\n",
            "None M\n",
            "None M\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#read the training data\n",
        "train_data = []\n",
        "height_data = []\n",
        "weight_data = []\n",
        "age_data = []\n",
        "\n",
        "\n",
        "with open('train.txt','r') as fileT:\n",
        "  for line in fileT:\n",
        "    result = line.strip().split(',')\n",
        "    y = result[3].replace(')','').strip() #strip white spaces and split based on comma\n",
        "    x1 = float(result[0].replace('(','').strip())\n",
        "    x2 = float(result[1].strip())\n",
        "    x3 = float(result[2].replace(')','').strip())\n",
        "    train_data.append([x1,x2,x3,y]) #return as an array of features and class label\n",
        "\n",
        "tree = DTL(train_data,3,get_default_class(train_data),0,given_depth,-1)\n",
        "tree.print_tree()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier\n",
        "\n",
        "correct_count = 0\n",
        "total_count = 0\n",
        "test_data = []\n",
        "with open('test.txt','r') as fileT:\n",
        "  for line in fileT:\n",
        "    result = line.strip().split(',')\n",
        "    y = result[3].replace(')','').strip() #strip white spaces and split based on comma\n",
        "    x1 = float(result[0].replace('(','').strip())\n",
        "    x2 = float(result[1].strip())\n",
        "    x3 = float(result[2].replace(')','').strip())\n",
        "    test_data.append([x1,x2,x3,y])\n",
        "    y_prediction = tree.predict((x1,x2,x3),given_depth)\n",
        "    total_count += 1\n",
        "    if(y == y_prediction):\n",
        "      correct_count += 1\n",
        "accuracy = correct_count/total_count\n",
        "print('test data accuracy is :',accuracy*100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAnnsnhrZD2n",
        "outputId": "5bdcb81f-e5da-40c4-c39f-b5922127d59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data accuracy is : 73.33333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_count_train = 0\n",
        "\n",
        "for train in train_data:\n",
        "  y_train_prediction = tree.predict((train[0],train[1],train[2]),given_depth)\n",
        "  if(train[3] == y_train_prediction):\n",
        "    correct_count_train += 1\n",
        "\n",
        "train_accuracy = correct_count_train/len(train_data)\n",
        "print('train data accuracy is :',train_accuracy*100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8pNIrIWjHsF",
        "outputId": "c0ab495f-1a46-49a5-f99a-9606a33f785f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data accuracy is : 76.66666666666667\n"
          ]
        }
      ]
    }
  ]
}