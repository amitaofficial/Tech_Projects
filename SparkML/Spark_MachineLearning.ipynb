{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_MachineLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPeJuQIp4dcFerrzGnRxiK0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lce4Uzwykt1"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-TTI1NizhOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrV8Y8FNyoMJ"
      },
      "source": [
        "#importing the sparkContext and sparkfame\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "# importing the SQL context\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.types import *\n",
        "#importing the VectorAssembler \n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.stat import Correlation\n",
        "# Importing the string indexer to convert categorial values to continous\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "# importing DecisionRegressor to get the prediction values\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "\n",
        "conf = SparkConf()\n",
        "conf.setMaster('local')\n",
        "# set the app name\n",
        "conf.setAppName('5433')\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "sqlContext = SQLContext(sc)\n",
        "# laod the csv file \n",
        "df = sqlContext.read.format('csv').options(\n",
        "    header='true', inferschema='true').load(\"hdfs:///user/amita/spark/dataset.csv\")\n",
        "#show the contents of the csv file\n",
        "df.show()\n",
        "# converting the gender categorial values into continous values\n",
        "gender_indexer = StringIndexer(inputCol=\"gender\", outputCol=\"Gender\")\n",
        "df = gender_indexer.fit(df).transform(df)\n",
        "# converting the gender categorial values into continous values\n",
        "race_indexer = StringIndexer(inputCol=\"race/ethnicity\", outputCol=\"Race/ethnicity\")\n",
        "df = race_indexer.fit(df).transform(df)\n",
        "# converting the parental level of education categorial values into continous values values\n",
        "parental_indexer = StringIndexer(inputCol=\"parental level of education\", outputCol=\"PArental level of education\")\n",
        "df = parental_indexer.fit(df).transform(df)\n",
        "# converting the lunch categorial values into continous values\n",
        "lunch_indexer = StringIndexer(inputCol=\"lunch\", outputCol=\"Lunch\")\n",
        "df = lunch_indexer.fit(df).transform(df)\n",
        "# converting the test preparation course categorial values into continous values\n",
        "test_indexer = StringIndexer(inputCol=\"test preparation course\", outputCol=\"Test preparation course\")\n",
        "df = test_indexer.fit(df).transform(df)\n",
        "#dispaly the columns in continous values\n",
        "df.show()\n",
        "# creating the vectors for the columns\n",
        "vector_features_col = 'features'\n",
        "# creating Vector Assembler\n",
        "vectorAssembler = VectorAssembler(\n",
        "inputCols=['reading score','math score','Gender','Race/ethnicity','PArental level of education','Lunch','Test preparation course'], outputCol=vector_features_col)\n",
        "df_vector1 = vectorAssembler.transform(df).select(\n",
        "[vector_features_col, 'writing score'])\n",
        "#prediction using decision regression \n",
        "dt = DecisionTreeRegressor(\n",
        "featuresCol=vector_features_col, labelCol='writing score')\n",
        "dt_model = dt.fit(df_vector1)\n",
        "# prediction using df_vector1\n",
        "dt_predictions = dt_model.transform(df_vector1)\n",
        "# show the prediction output\n",
        "dt_predictions.show()\n",
        "#evaluate accuracy using regression evaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "dt_evaluator = RegressionEvaluator(\n",
        "    labelCol=\"writing score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "# getting the accuracy if prediction\n",
        "rmse = dt_evaluator.evaluate(dt_predictions)\n",
        "# print the accuracy value\n",
        "print(\"accuracy (RMSE) on test data = %g\" % rmse)\n",
        "dt_predictions.describe().show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
